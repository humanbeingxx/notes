# 高可用

## 主副本

### 主副之间数据同步机制

[同步流程](../attach/kafka主从数据同步流程.png)

min.insync.replicas=1 表示一旦消息被写入leader的磁盘，就认为是已提交。

可能存在的问题：

1. 数据丢失

kafka中follower的HW是延迟更新，先同步数据，再更新HW。

B1: MSG1, MSG2
B2: MSG1, MSG2

B1是leader，HW1=2， B2是follower，HW2=1。

此时B2重启，重启后的LEO截断为HW，B2中只剩下一条MSG1。之后B1挂了，重启后变成follower，此时会同步B2的数据，截断为HW=1，导致MSG2丢失。

2. 数据不一致

B1: MSG1, MSG2
B2: MSG1

B2还没有同步MSG2，此时B1、B2同时挂掉，且B2先恢复，成为leader。

此时B2写入MSG3，变成 B2: MSG1, MSG3。之后B1恢复，成为follower，且和B2进行同步，但是此时双方的HW都是2，不需要截断和更新，造成数据不一致。

***解决方案***

引入leader epoch，在内存为每个分区缓存epoch数据，并定期持久化到checkpoint文件中。follower请求同步leader数据时会带上当前的epoch，leader返回该epoch结束下一条日志的位置。

解决数据丢失问题：B2重启后，先不截断，而是请求leader当前epoch对应的位置，B1 B2中的消息epoch都是0，因此leader返回3，follower判断LEO没有大于等于3，不进行截断。

解决数据不一致问题：B2恢复后，仍然会进行日志截断，只保留MSG1（这里的数据仍会丢失），此时B2的leader epoch增加为1。B1恢复后，请求leader epoch为0对应的LEO是2，B1需要截断2以后的日志，从而只保留了MSG1。