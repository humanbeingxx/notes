# 神经网络

由于神经网络的突出表现，这里单放一个总结。

## CNN（卷积神经网络）

一个CNN由下面几个部分构成。

1. 卷积层。提取输入的不同特征，多层的网络能从低级特征中迭代提取更复杂的特征。
2. 池化层。卷积层之后会得到维度很大的特征，将特征切成几个区域，取其最大值或平均值，得到新的、维度较小的特征。
3. 全连接层。把所有局部特征结合变成全局特征，用来计算最后每一类的得分。

但是并不是每种只有一层。可以是 卷积层 -> 池化层 -> 卷积层 -> 卷积层 -> 池化层 -> 全连接层 等方式构建一个复杂的网络。

下面是一个公式化一点的定义：

`INPUT -> [[CONV -> RELU]*N -> POOL?]*M -> [FC -> RELU]*K -> FC`

### 卷积层

### 卷积核

给定输入的数据（矩阵），将一个小区域内的数据加权平均后作为输出的一个数据元素，这里加权方式是一个函数，这个函数就叫卷积核。

例如二维矩阵，某个点的输出就是它和周围8个点，通过卷积核计算后，得到了一个新的值。

### Zero Padding

在原始数据基础上往四周填充0。除了在尺寸上的意义，这么做还能保持边界信息。否则每次卷积或者下采样，导致尺寸减少，边界数据都只会计算一次，边界信息会逐步丢失。

### 池化层（下采样）

目的是为了减少特征。规模一般是2x2，采用最大值或者平均值的方法，将区域内的特征值压缩成一个特征。

通过下采样，在尽可能的情况下，减少数据尺寸，防止过拟合。

最长采用的是最大值方法(MaxPooling)。由于我们设置的不同的卷积核能提取不同类型的特征，MaxPooling操作一般都能保留最能体现该特征的数值。当然也不是所有情况下效果都好，此时可以对比使用和不适用两种情况下模型的表现。

### 全连接层

### Softmax

即使是分类问题，激励函数也不止输出0和1，而是输出各个类别的概率。

```math
\sigma_{i}(z) = \frac{e^{z_{i}}}{\sum_{j=1}^{J}e^{z_{i}}}
```

每个输入计算指数，并取各个指数值的比例。

